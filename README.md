# snn-Expected-Free-Energy
  ## 预期自由能+snn，随便了，如果以大模型的术语来说，就是，我此刻是否选择行动，是以这个行动会不会被后续节点注意到，注意到多少，为依据。尽可能多的选会被后续token计算中注意到的行为，最大化这个被注意程度，不过是snn版。



  ## 人工生命需要完成的事
    人工生命可以视为是一团可以在变化的环境中维持自身存在的集体，而无法维持存在<能维持存在（在变化到达边界时再处理）<预先切换边界状态以使得变化发生时，自身改动最小化。
    （等到事情发生时再反应和能够预先做准备，能完成的事是不一样的，可以说后者有着压倒性的存在优势）
  这就引出了预测的需要，预测的需要要求生命能够预测全部边界的下一刻的变化（对于snn来说，就是一固定输入的下一个激活）（整个预测系统是为之服务的）（生命内外存在边界，而唯一能确定的就是下一刻生命所需要处理的实际外部输入，除此之外再无内外部交互可言）。
  
    而对于snn来说，则就是固定输入宽度的信息流，不断更改内部结构和连接去拟合这个信息流输入的过程。
  而有些条件是无法单纯通过调整内部认知改变的（例如，你无法靠认知说服自己不饿，血糖值的变化，酮症的出现，它们需要进食行为来更迭。）
  而对于snn来说，就是一个行动节点能在什么上下文中干预多少节点（或者说对多少的节点的预测提供多少比例的比重，把这个比重，收集起来，然后回传到上下文节点中去，利用双指数函数先增后减来拟合这个比重参数，然后有了稳定的比重参数，就在前置节点激活之后去用带热量的sofmax函数计算，热量又恰好能跟分数准确率挂钩，最后分数越高的行为会被选中，这一定程度上又是符合预期自由能原理的。）
  这里还有一个认识是，一个节点激活前，一定有一组节点与之相关，导致了它的激活，这可能跟llm的上下文是极为相似的，但是不同的是，这回的上下文隐藏在诸多节点之中（这里面肯定有环！！！但是环的训练估计要粗粒化，数学推导估计是个大工程）。
  这里就又涉及到了条件反射的建立（我是这样想的，一开始的婴儿是会自动的吮吸，而知识随着网络的深度不断增加而逐渐建立，逐渐前移到咀嚼，前移到烹饪，前移到甚至上班，学习等）
  
    这个过程中还有个感知是，对于那些需要维持一定水平的参数，它即服从外界感知（血糖水平），又受行为和环境影响。把每个水平的变化反过来找到其原因，这些原因中有行动节点的干预，从而反向的向行动节点提供分数，这个分数又会散到snn网络中去。
  整体架构就搭起来了。
  
  （变化的功能才能承载变化的结构，一群节点的初始连接可能不固定，但是它们都受一定的边界输入信息流的约束）
  
  
  补档：两跳和多跳其实可以直接延用当前行动节点的训练逻辑(区别在于，内部节点激活不会直接导致行为发生)，那么剩下的就是数学上保持原有特性不变，然后尝试做运算上的替换了或者直接硬件上去做一些优化了。现在的架构整体上对计算的压力还是太大了。
